# Volatility Models

```{r setup4, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,  warning=FALSE, message=FALSE, fig.pos='h')
options(digits=4, width=60)
library(fpp3)
library(patchwork)
library(purrr)
library(tidyverse)

```

\pagenumbering{arabic}

**This chapter is heavily based on Chapter 12 of @chatfield2019analysis and Chapter 3 of @tsay2010analysis .**

## Introduction

- Anything that is observed sequentially over time is a time series.

<!--Tsay-->
- **Financial time series** analysis focuses on the theory and practice of asset valuation over time.
     
<!--Asset valuation is the process of determining the current value of a company's assets, such as stocks, buildings, equipment, brands, goodwill, etc.

https://www.quora.com/What-is-the-difference-between-time-series-methods-and-financial-time-series-methods
As the names suggest, Financial TS methods are a subset of TS methods.

At the end, Financial TS is times series analysis trying to capture different aspects of financial data that we do not see in general in other economics data.

-->
- In finance, the data can be collected much more frequently -- High frequency data.
<!-- High frequency data provide a rich source of information on the micro-structure of financial markets.-->
<!--Hence, we may need to use continuous time econometrics instead of discrete time.-->
- Many financial time series also exhibit changing variance and this can have important consequences in formulating  financial decisions.

<!--Another famous extension in finance is time varying variance and covariances (GARCH, Stochastic Volatility etc).-->


**Example: Financial time series**

- Typically, when we analyze assets, we look at the percentage change in prices or returns.

```{r sp500, cache=TRUE, echo=TRUE, fig.cap="Daily returns of the adjusted closing prices of the Standard & Poor's 500 (S&P500) index from January 4, 1995 to February 25, 2021"}
# Tidy financial analysis 
library(tidyquant)

sp500 <- tq_get("^GSPC", from = "1995-01-04", to = "2021-02-25" )
print(sp500)

# Convert each assets raw adjusted closing prices to returns
sp500_return <- sp500 %>% 
  tq_transmute(select     = adjusted, 
               mutate_fun = periodReturn, 
               period     = "daily")

sp500_return %>% 
  as_tsibble(index = date) %>%
  autoplot(daily.returns) +
  labs(x = "Day", y= "Daily return")

```

   - The mean of the return series seems to be stable with an average return of approximately zero.
   - The volatility of data changes over time.

- The focus of this chapter is to study some methods and econometric models for modeling the **volatility** (conditional standard deviation) of an asset return. <!--tsay Volatility means the conditional standard deviation of the underlying asset return.-->
- These models are referred to as **conditional heteroscedastic models**.
<!--https://stats.stackexchange.com/questions/41509/what-is-the-difference-between-garch-and-arma - What is the difference between GARCH and ARMA?-->
- These models do not generally provide better point forecasts, but provides a better estimates of the (local) variance.
- As a result they allow to compute   more reliable prediction intervals and therefore a better assessment of risk. 
- Volatility models have many applications in economics and finance.
- This chapter discusses various types of **univariate volatility models**


## Structure of a Model for Asset Returns

- Let, $\{P_T\}$, denotes a time series.

- Let, $\{Y_T\}$, denotes a derived series from which any trend and seasonal effects have been removed and  linear (short-term correlations) effects may also have been removed.
  - Examples : Let  $\{P_T\}$ be share price at the $t$th trading day.
  
  $$Y_t=log P_t - log P_{t-1} \text{  or  } Y_t = \frac{P_t-P_{t-1}}{P_{t-1} }\times100\%$$
   
<!--$\{Y_T\}$ might be the first differences (or percentage changes) of financial time series such as the natural log of a share price $\{P_T\}$
-->
   - This is often called the **return** or the **growth rate** of a series.

**Example**

- Let $P_t$ be the adjusted closing prices of the S&P500 at the $t$th trading day.
- Let $Y_t$ be the daily returns of the S&P500 Index at each day as shown in Figure \@ref(fig:sp500).
- The basic idea in volatility modelling is that the return series $\{Y_t\}$ has very few serial correlations, but it is a dependent series.
- Consider the sample ACFs and PACFs of $Y_t$, $|Y_t|$ and $Y_t^2$ (Figure \@ref(fig:acf))


```{r acf, message=FALSE, warning=FALSE, fig.pos='h', fig.cap="Sample ACF (left) and sample PACF (right) of various functions of the daily returns, $Y_t$, of adjusted closing prices of S&P500 Index from from January 4, 1995 to February 25, 2021. Top: Original series $Y_t$; Middle: Absolute value of $Y_t$; Bottom: Squared values of $Y_t$." }
data <- sp500_return %>% 
  mutate(yt= daily.returns, 
         absyt = abs(daily.returns),
         sqyt = daily.returns^2) %>%
  as_tsibble(index = date, regular=FALSE)

p1<- data %>% ACF(yt) %>% autoplot()
p2<- data %>% PACF(yt) %>% autoplot()
p3<- data %>% ACF(absyt) %>% autoplot()
p4<- data %>% PACF(absyt) %>% autoplot()
p5<- data %>% ACF(sqyt) %>% autoplot()
p6<- data %>% PACF(sqyt) %>% autoplot()

(p1|p2)/
  (p3|p4)/
  (p5|p6)
```

  - Sample ACFs the returns $Y_t$ suggest no significant serial correlations except for small ones at lags 1, 3 and 5.
  - However, the sample ACFs of $|Y_t|$ and  $Y_t^2$, show strong dependence over all lags.
  - Important feature: the returns may seem serially uncorrelated, but it is dependent.
  - This is a common observations for daily returns series
  
<!-- 
https://stats.stackexchange.com/questions/325390/serially-uncorrelated-but-dependence-in-arch-model

Serially Uncorrelated but dependence in ARCH model

On the first chart (of raw returns), the ACF does not appear to be significantly non-0 anywhere (other than at lag 1 of course). In other words, there is no serial correlation of the returns.

On the second chart (of squared returns), the ACF does appear to be significantly non-0 at certain lags. So this gives us hope that we can use these squared returns to predict something by using them.

(Interestingly, if you plotted the ACF for absolute returns, you would find something similar to the second chart. This is because the absolute value and the square both discard the sign to measure some sort of "deviation", in the non-technical sense of the word.)

It's not just any series, it's a series of raw returns. And as you saw in the first chart, raw returns are not serially correlated.

However, squared (and absolute) returns are, which is good news! This is because we can now use them to predict "volatility" (i.e. the conditional variance) using ARCH models. And this is what ARCH models do-->


<!-- To focus our discussion on volatility of return series, we may further assume that Yt-->

**Volatility of a return series**

- Let $Y_t$ be the innovations in a linear time series model.
<!--  the innovation is the difference between the observed value of a variable at time t and the optimal forecast of that value based on information available prior to time t.

 I conclude that innovations are ok to interchange with errors. It's called innovations because in time series context the errors bring new information to the system.-->
- Let $X_t$ follow an $ARMA(p,q)$ model,
$$\phi(B)X_t=\theta(B)Y_t,$$

where $\phi(B)$ and $\theta(B)$ are polynomials of $B$ with order $p$ and $q$, respectively.
- Let $\mathcal{F}_t$, the set of observed data up to time $t$, (i.e. $\{X_1,X_2,\dots, X_t\}$).
- Then the observation $X_t$ can be written as 
$$X_t=\mu_t+Y_t,$$
where $\mu_t$ is the mean of $X_t$ conditional on observed data $\mathcal{F}_{t-1},$

$$\mu_t=E(X_t|\mathcal{F}_{t-1})= \phi(B)X_t-(\theta(B)-1)Y_t$$

and  the innovation series $Y_t$ has mean 0 and conditional variance

$$\sigma_t^2=Var(X_t|\mathcal{F}_{t-1})=Var(Y_t|\mathcal{F}_{t-1})$$
- The conditional heteroscedastic models of this chapter are concerned with the evolution of  $\sigma_t^2$ over time.
- The model for $\mu_t$ is referred to as the mean equation for $X_t$ and the model for $\sigma^2_t$ is the volatility equation for $X_t.$

<!--
- A classical linear regression model assumes that the innovation series $Y_t$  has a constant variance.
- The fundamental idea in GARCH is to add a second equation to the standard regression model, the conditional variance equation. 

-->

## Model Building

<!--Tsay: Analysis of financial ts pg 113-->

The process of building a volatility model for an asset return series consists of four main steps [@tsay2010analysis]:

   1. Specify a mean equation by testing for serial dependence in the data and, if necessary, building an econometric model (e.g., an ARMA model) for the return series to remove any linear dependence.
   2. Use the residuals of the mean equation to test for ARCH effects.
   3. Specify a volatility model if ARCH effects are statistically significant, and perform a joint estimation of the mean and volatility equations.
   4. Check the fitted model carefully and refine it if necessary.


## Testing for ARCH Effect

- Let $Y_t = X_t − \mu_t$ be the residuals of the mean equation.
- The squared series $Y_t^2$ is then used to check for **conditional heteroscedasticity** (also known as the **ARCH effects**).
- Volatility clustering implies a strong autocorrelation in squared series. 
- There are two statistical tests for conditional heteroscedasticity 
   1. Method 1: Apply the usual Ljung–Box statistics $Q(m)$ to the $Y_t^2$  (McLeod and Li, 1983). 
   
      - The null hypothesis is that the first $m$ lags of ACF of the $Y_t^2$ series are zero.

   2. Method 2: The Lagrange multiplier test of Engle (1982). 

## Autoregressive Conditional Heteroskedastic (ARCH) Models

- ARCH model of Engle (1982) is the first model that provides a systematic framework for volatility modeling.

-  Main idea:  
   
   (a) $Y_t$ is serially uncorrelated, but dependent,    (b) the dependence of $Y_t$ can be described by a simple quadratic function of its lagged values. 

- To better describe the idea, we represents $Y_t$ having a zero means in the form 

\begin{equation} \label{eq:1}
Y_t=\sigma_t\epsilon_t,
\end{equation}

\begin{equation} \label{eq:2}
\sigma_t^2 =\alpha_0+\alpha_1Y_{t-1}^2+\dots+\alpha_mY_{t-m}^2,
\end{equation}

where $\{\epsilon_t\}$ denotes is a sequence of iid random variables with mean zero and variance 1. 

- $\sigma_t$ can be thought of as the local conditional standard deviation of the process.
- $\alpha_0>0$, and $\alpha_i\geq0$ for $i > 0$. - To ensure that the unconditional variance of $Y_t$ is finite, coefficients $\alpha_i$ must satisfy some regularity conditions. 
- The $\epsilon_t$ may  follow the standard normal or a standardized Student-t or a generalized error distribution.

<!--From the structure of the model, it is seen that large past squared shocks {a2 }m t−i i=1
imply a large conditional variance σt2 for the innovation at . Consequently, at tends to assume a large value (in modulus). This means that, under the ARCH framework, large shocks tend to be followed by another large shock. Here I use the word tend because a large variance does not necessarily produce a large realization. It only says that the probability of obtaining a large variate is greater than that of a smaller variance. This feature is similar to the volatility clustering observed in asset returns.-->

- A model for $Y_t$ satisfying  Equations \ref{eq:1} and \ref{eq:2} is called an  **autoregressive conditional heteroskedastic model** of order $m$ ($ARCH(m)$)
- Note that Equation \ref{eq:2} does not include an 'error' term and therefore does not define a stochastic process.
- The ARCH model allows for volatility clustering as the conditional variance $\sigma_t^2$ in Equation \ref{eq:2} depends on the lagged squared innovations $Y^2_{t−1}$. A large (positive or negative) residual at time $t − 1$ implies that $Y^2_{t−1}$ is large and consequently the conditional variance $\sigma_t^2$ will be large as $\alpha_i ≥ 0$. Thereby, large shocks tend to be followed by large shocks (in absolute terms) and small shocks tend to be followed by small shocks (in absolute terms). This is the feature we call **volatility clustering**.

-  However, large variance does not necessarily produce a large **realization**. It only says that the **probability** of obtaining a large variate is greater than that of a smaller variance. 

### Example: Building an ARCH Model

- Let's apply the modeling procedure to build a simple ARCH model for the daily returns, $Y_t,$ of adjusted closing prices of the S&P500 index.

- Figure \@ref(fig:sp500) shows the daily return series from January 4, 1995 to February 25, 2021.
- The sample ACF and PACF of the squared returns in the bottom panel of Figure \@ref(fig:acf), show the existence of conditional heteroscedasticity.
- If an ARCH effect is found to be significant, one can use the PACF of $Y_t^2$ to determine the ARCH order.
- We consider an ARCH(2) model  with the following specification for the daily return series

$$X_t=\mu+Y_t,$$
$$Y_t=\sigma_t\epsilon_t,$$
$$\sigma_t^2=\alpha_0+\alpha_1Y_{t-1}^2 + \alpha_2Y_{t-2}^2.$$

- We use the R function `garchFit` in the R package `fGarch` to estimate the model.

```{r arch, echo=TRUE, results="hide", message=FALSE, warning=FALSE}
# install.packages("fGarch")
library(fGarch)
fit1 <- garchFit(~garch(2,0), data =sp500_return$daily.returns)
summary(fit1)
```

```{r archprint, echo=FALSE}
summary(fit1)
```


**Plot the result**

```{r plot, echo=TRUE}
sp500_return <- sp500_return %>%
  mutate(vol = volatility(fit1),
         resid.st = residuals(fit1, standardize=T)) %>%
  as_tsibble(index = date, regular = FALSE)

p1 <- sp500_return %>% autoplot(vol)
p2 <- sp500_return %>% autoplot(resid.st)  
p3 <- sp500_return %>% ACF(resid.st) %>% autoplot()
p4 <- sp500_return %>% PACF(resid.st) %>% autoplot()
p5 <- sp500_return %>% ACF(resid.st^2) %>% autoplot()
p6 <- sp500_return %>% PACF(resid.st^2) %>% autoplot()
```

```{r plot2, echo=FALSE, fig.cap= "(a) Estimated volatility $\\hat{\\sigma_t}$, (b) the standardized residual $\\hat{\\epsilon_t}$, (c) sample ACF of $\\hat{\\epsilon_t}$,  (d) sample PACF of $\\hat{\\epsilon_t}$, (e) sample ACF of $\\hat{\\epsilon_t^2}$,  (d) sample PACF of $\\hat{\\epsilon_t^2}$, in the ARCH(2) model for daily returns of adjusted closing prices of the S&P500 Index from January 4, 1995 to February 25, 2021."  }
p<- (p1 | p2) /
  (p3 | p4) /
  (p5 | p6)

p +
  plot_layout(guide = 'collect') +
  plot_annotation(tag_levels = 'a')
```

\newpage  
- Assuming that $\epsilon_t$ are iid, standard normal, we get the fitted model as follows:

$$X_t = 0.0007804_{(1.098e-04)} + Y_t, \text{  }Y_t=\sigma_t\epsilon_t,$$

$$\sigma_t^2=0.00005883_{(1.818e-06)}+0.2212_{(1.967e-02)}Y_{t-1}^2 + 0.3873_{(2.368e-02)}Y_{t-2}^2$$

where the standard errors of the parameters are given in the parentheses.

- Both the output and the plot show that the estimated residuals still have conditional heteroscedasticities. 
- Therefore, the ARCH(2) model is not adequate.

## Generalized ARCH (GARCH) Models

- Although the ARCH model is simple, it often requires many parameters to adequately describe the volatility process of an asset return.

- Bollerslev (1986) proposes a useful extension known as the generalized ARCH (GARCH) model.

- The ARCH model has been generalized to allow the variance to depend on past values of $Y_t^2$ as well as on past values of $\sigma^2_t.$

-  A model for $Y_t$ satisfying  Equations \ref{eq:1} is said to follow a  **generalized ARCH (or GARCH) model** of order $(m,s)$  ($GARCH(m,s)$) when the local conditional variance is given by

\begin{equation} \label{eq:3}
\sigma_t^2 =\alpha_0+\sum_{i=1}^m\alpha_iY_{t-i}^2+\sum_{j=1}^s\beta_j\sigma_{t-j}^2,
\end{equation}

where $\{\epsilon_t\}$ is a sequence of iid random variables with mean 0 and variance 1, $\alpha_0>0,$ $\alpha_i\geq0,$ $\beta_j\geq0,$ and
$\sum_{i=1}^{max(m,s)}(\alpha_i+\beta_j)<1.$ 

- Here, $\alpha_i=0$ for $i>m$ and $\beta_j =0$ for $j>s.$

- The constraint on $\alpha_i+\beta_j$ implies that the unconditional variance of $Y_t$ is finite, whereas its conditional variance $\sigma_t^2$ evolves over time. 

- $\epsilon_t$ is often assumed to follow a standard normal or standardized Student-t distribution or generalized error distribution.

- Equation \ref{eq:3} reduces to a pure ARCH($m$) model if $s = 0$ (i.e. GARCH($m,0$)). 

- The $\alpha_i$ and $\beta_j$ are known as ARCH and GARCH parameters, respectively.

To understand properties of GARCH models, it is informative to use the following representation.

- Let $\eta_t = Y_t^2 − \sigma_t^2.$ 
- Then $\sigma_t^2= Y_t^2 −\eta_t.$
-By plugging $\sigma_{t-1}^2= Y_{t-1}^2 −\eta_{t-1}$ ($i=0,\dots,s$) into Equation \ref{eq:3}, we get the GARCH model as 
\begin{equation} \label{eq:4}
Y_t^2 =\alpha_0+\sum_{i=1}^{max(m,s)}(\alpha_i+\beta_i)Y_{t-i}^2+\eta_t-\sum_{j=1}^s\beta_j\eta_{t-j}.
\end{equation}


- It is easy to check that $\{\eta_t \}$ is a martingale difference series [i.e., $E(\eta_t ) = 0$ and $cov(\eta_t , \eta_{t-j} ) = 0$ for $j\geq 1$]. 
- However, $\{\eta_t \}$ in general is not an iid sequence.
- Equation \ref{eq:4} is an ARMA form for the squared series $Y_t^2$.
- Therefore, a GARCH model can be regarded as an application of the ARMA idea to the squared series $Y_t^2$. 


**GARCH($1,1$) model**

- The $GARCH(1,1)$ model is  often used to fit financial time series.
- The properties of GARCH models can easily be understood by focusing
on the simplest $GARCH(1,1)$ model with

$$\sigma_t^2 = \alpha_0+\alpha_1Y_{t-1}^2 + \beta_1\sigma_{t-1}^2, \text{  } 0\leq\alpha_1, \beta_1\leq 1, (\alpha_1+\beta_1)<1.$$
- The model implies that a large $Y_t^2$ or $\sigma_{t-1}^2$ will lead to a large $\sigma_{t}^2$, which in turn will give rise to a large $Y_t^2=\sigma_t^2\epsilon_t^2.$
- This again generate the well-known behaviour of volatility clustering in financial time series. 

### Prediction of volatilities

- Both ARCH and GARCH models do not affect point forecasts of the original observed variables.
- Therefore, it is difficult to make a fair comparison of the forecasting abilities of different models for changing variance. 
- Therefore, both the modeling aspect (understanding the changing structure of a series), and the assessment of risk, are more important than  their ability to make point forecasts.
- Forecasts of a GARCH model are similar to those of an ARMA model.
- Consider the GARCH(1,1) model.
- Let the forecast origin is $h$.
- For 1-step ahead forecast, we have

$$\sigma_{h+1}^2 = \alpha_0+\alpha_1Y_h^2+\beta_1\sigma_h^2$$
where $Y_h$ and $\sigma_h^2$ are known at the time index $h$.

- Then, 1-step ahead forecast is  

$$\sigma_{h}^2(1) = \alpha_0+\alpha_1Y_h^2+\beta_1\sigma_h^2.$$
- For multistep-ahead forecasts, we use $Y_t^2 = \sigma_t^2\epsilon_t^2.$ 
- Then the volatility equation can be written as

$$\sigma_{t+1}^2 = \alpha_0+(\alpha_1+\beta_1)\sigma_t^2+\alpha_1\sigma_t^2(\epsilon_t^2-1).$$
- When $t = h + 1$, we get,

$$\sigma_{h+2}^2 = \alpha_0+(\alpha_1+\beta_1)\sigma_{h+1}^2+\alpha_1\sigma_{h+1}^2(\epsilon_{h+1}^2-1).$$
-  Since $E(\epsilon_{h+1}^2-1|\mathcal{F}_t)=0$, the 2-step-ahead volatility forecast at the forecast origin $h$ satisfies the equation

$$\sigma_{h}^2(2) = \alpha_0+(\alpha_1+\beta_1)\sigma_h^2(1).$$

- In general, we can write
$$\sigma_{h}^2(k) = \alpha_0+(\alpha_1+\beta_1)\sigma_h^2(k-1), \quad k>1.$$

- This result is similar to an ARMA(1,1) model with AR polynomial $1 − (\alpha_1 + \beta_1)B$.

### Example: Building a GARCH Model

- Let's apply the modeling procedure to build a $GARCH(1,1)$ model for the daily returns, $Y_t,$ of adjusted closing prices of the S&P500 index.
- Figure \@ref(fig:sp500) shows the daily return series from January 4, 1995 to February 25, 2021.
- The sample ACF and PACF of the squared returns in the bottom panel of Figure \@ref(fig:acf), show the existence of conditional heteroscedasticity.

```{r garch, echo=TRUE, results="hide", message=FALSE, warning=FALSE}
# install.packages("fGarch")
library(fGarch)
fit2 <- garchFit(~garch(1,1), data =sp500_return$daily.returns)
summary(fit2)
```

```{r garchprint, echo=FALSE}
summary(fit2)
```


**Plot the result**

```{r plot3, echo=TRUE}
sp500_return <- sp500_return %>%
  mutate(vol = volatility(fit2),
         resid.st = residuals(fit2, standardize=T)) %>%
  as_tsibble(index = date, regular = FALSE)

p1 <- sp500_return %>% autoplot(vol)
p2 <- sp500_return %>% autoplot(resid.st)  
p3 <- sp500_return %>% ACF(resid.st) %>% autoplot()
p4 <- sp500_return %>% PACF(resid.st) %>% autoplot()
p5 <- sp500_return %>% ACF(resid.st^2) %>% autoplot()
p6 <- sp500_return %>% PACF(resid.st^2) %>% autoplot()
```

```{r plot4, echo=FALSE, fig.cap= "(a) Estimated volatility $\\hat{\\sigma_t}$, (b) the standardized residual $\\hat{\\epsilon_t}$, (c) sample ACF of $\\hat{\\epsilon_t}$,  (d) sample PACF of $\\hat{\\epsilon_t}$, (e) sample ACF of $\\hat{\\epsilon_t^2}$,  (d) sample PACF of $\\hat{\\epsilon_t^2}$, in the GARCH(1,1) model for daily returns of adjusted closing prices of the S&P500 Index from January 4, 1995 to February 25, 2021."  }
p<- (p1 | p2) /
  (p3 | p4) /
  (p5 | p6)

p +
  plot_layout(guide = 'collect') +
  plot_annotation(tag_levels = 'a')
```

```{r}
## predict -
   predict(fit2, n.ahead = 10)
   predict(fit2, n.ahead = 10,mse="uncond")

## predict with plotting: critical values = +- 2

   predict(fit2, n.ahead = 10, plot=TRUE, crit_val=2)


```
- Now the model is adequate as the standardized residuals in the fitted $GARCH(1,1)$ model show little conditional heteroscedasticity.

## The ARMA-GARCH Models

## References:

- Chatfield, C., & Xing, H. (2019). The analysis of time series: an introduction with R. CRC press.

- Tsay, R. S. (2010). Analysis of Financial Time Series. John Wiley & Sons..
\newpage
