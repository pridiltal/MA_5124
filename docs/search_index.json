[["index.html", "MA 5124 Financial Time Series Analysis &amp; Forecasting Course Syllabus Pre-requiites Learning Objectives Learning Outcomes Outline Syllabus Method of Assessment Lecturer Schedule Copyright Notice", " MA 5124 Financial Time Series Analysis &amp; Forecasting Dr. Priyanga D. Talagala 2021-01-10 Course Syllabus Module Code: MA 5124 Title: Financial Time Series Analysis &amp; Forecasting Credits: 4 Pre-requiites None Learning Objectives The purpose of this course is to provide students with introductory tools for the time series analysis of financial time series. Analyze of data series based on stochastic and non stochastic models Learning Outcomes On successful completion of this course, students will be able to provide more than an introductory treatment of the topics. Students are encouraged to pursue further study in this area if they find that the topics covered in this course. Outline Syllabus Definition and examples of time series back-shift and differencing-operators, - strong and weak stationarity, definition of ACF, PACF. Definitions and properties of the \\(MA(q), MA(\\infty), AR(p), AR(\\infty)\\) and \\(ARMA(p,q)\\),in particualr their acf’s causal stationarity of AR invertibility of MA models and causal stationarity and invertibility of ARMA; - concept of spectral density function and its applications definition and properties of integrated \\(ARIMA(p,d,q)\\) processes definition and properties of random walks with or without drift. Model selection following the AIC and BIC brief introduction to linear prediction and calculation of forecasting intervals for normal ARMA models point and interval forecasts for normal random walks with or without drift. Definition and properties of the VAR (vector autoregressive) model, arrange a univariate time series as a multivariate Markov model. Nonlinear properties of financial time series definition and properties of the well known ARCH, GARCH etc. Cointegration in Single Equations, Modeling and Forecasting Financial Time Series. Method of Assessment Assignment 30% End-semester examination 70% Lecturer Dr. Priyanga D. Talagala Schedule Lectures: Sunday [9.00am -12.00 noon] Copyright Notice My lectures and course materials, including presentations, tests, exams, outlines, and similar materials, are protected by copyright. I am the exclusive owner of copyright in those materials I create. I encourage you to take notes and make copies of course materials for your own educational use. However, you may not, nor may you knowingly allow others to reproduce or distribute lecture notes and course materials publicly without my express written consent. "],["intro.html", "Chapter 1 Intordution to Time Series Forecasting", " Chapter 1 Intordution to Time Series Forecasting "],["arima-models.html", "Chapter 2 ARIMA models 2.1 Stationarity and differencing", " Chapter 2 ARIMA models AR: autoregressive (lagged observations as inputs) I: integrated (differencing to make series stationary) MA: moving average (lagged errors as inputs) An ARIMA model is rarely interpretable in terms of visible data structures like trend and seasonality. But it can capture a huge range of time series patterns. 2.1 Stationarity and differencing 2.1.1 Stationarity Definition If \\(\\{y_t\\}\\) is a stationary time series, then for all \\(s\\), the distribution of \\((y_t,\\dots,y_{t+s})\\) does not depend on \\(t\\). A stationary series is: roughly horizontal constant variance no patterns predictable in the long-term Transformations help to stabilize the variance. For ARIMA modelling, we also need to stabilize the mean. Identifying non-stationary series time plot. The ACF of stationary data drops to zero relatively quickly The ACF of non-stationary data decreases slowly. For non-stationary data, the value of r1 is often large and positive. 2.1.2 Differencing Differencing helps to stabilize the mean. The differenced series is the change between each observation in the original series: \\(y&#39;_t = y_t - y_{t-1}\\). The differenced series will have only \\(T-1\\) values since it is not possible to calculate a difference \\(y_1&#39;\\) for the first observation. 2.1.3 Second-order differencing Occasionally the differenced data will not appear stationary and it may be necessary to difference the data a second time: \\[y&#39;&#39;_{t} = y&#39;_{t} - y&#39;_{t - 1}\\] \\[= (y_t - y_{t-1}) - (y_{t-1}-y_{t-2})\\] \\[= y_t - 2y_{t-1} +y_{t-2}.\\] \\(y_t&#39;&#39;\\) will have \\(T-2\\) values. In practice, it is almost never necessary to go beyond second-order differences. 2.1.4 Seasonal differencing A seasonal difference is the difference between an observation and the corresponding observation from the previous year. \\[y&#39;_t = y_t - y_{t-m}\\] where \\(m=\\) number of seasons. For monthly data \\(m=12\\). For quarterly data \\(m=4\\). Example : Electricity production usmelec %&gt;% autoplot( Generation ) usmelec %&gt;% autoplot( log(Generation) ) usmelec %&gt;% autoplot( log(Generation) %&gt;% difference(12) ) usmelec %&gt;% autoplot( log(Generation) %&gt;% difference(12) %&gt;% difference() ) Seasonally differenced series is closer to being stationary. Remaining non-stationarity can be removed with further first difference. If \\(y&#39;_t = y_t - y_{t-12}\\) denotes seasonally differenced series, then twice-differenced series is \\[y^*_t = y&#39;_t - y&#39;_{t-1}\\] \\[= (y_t - y_{t-12}) - (y_{t-1} - y_{t-13})\\] \\[= y_t - y_{t-1} - y_{t-12} + y_{t-13}.\\] When both seasonal and first differences are applied \\(\\dots\\) - it makes no difference which is done first—the result will be the same. - If seasonality is strong, we recommend that seasonal differencing be done first because sometimes the resulting series will be stationary and there will be no need for further first difference. It is important that if differencing is used, the differences are interpretable. 2.1.5 Interpretation of differencing first differences are the change between one observation and the next; seasonal differences are the change between one year to the next. But taking lag 3 differences for yearly data, for example, results in a model which cannot be sensibly interpreted. "],["exponential-smoothing.html", "Chapter 3 Exponential Smoothing", " Chapter 3 Exponential Smoothing "],["references.html", "References", " References "]]
